{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":94635,"databundleVersionId":13121456,"sourceType":"competition"},{"sourceId":282742,"sourceType":"modelInstanceVersion","modelInstanceId":239467,"modelId":222398}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers==4.41.1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T05:19:49.293917Z","iopub.execute_input":"2025-10-17T05:19:49.294183Z","iopub.status.idle":"2025-10-17T05:20:05.163788Z","shell.execute_reply.started":"2025-10-17T05:19:49.294155Z","shell.execute_reply":"2025-10-17T05:20:05.162720Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T05:20:48.304059Z","iopub.execute_input":"2025-10-17T05:20:48.304649Z","iopub.status.idle":"2025-10-17T05:20:48.308733Z","shell.execute_reply.started":"2025-10-17T05:20:48.304625Z","shell.execute_reply":"2025-10-17T05:20:48.307865Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import more_itertools\nimport torch\nimport pandas as pd\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModelForCausalLM\nfrom huggingface_hub import login\nfrom transformers import pipeline\nfrom sklearn.metrics import roc_auc_score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T05:20:05.182063Z","iopub.execute_input":"2025-10-17T05:20:05.182290Z","iopub.status.idle":"2025-10-17T05:20:25.848379Z","shell.execute_reply.started":"2025-10-17T05:20:05.182272Z","shell.execute_reply":"2025-10-17T05:20:25.847688Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class reddit_evaluator:\n    def __init__(self,model):\n        #self.rawdata = pd.read_csv('test.csv')\n        self.model_name = model\n        self.final_data = pd.DataFrame\n        self.load_model()\n\n\n    def HFtokenloader(self):\n        # Loading Token\n        user_secrets = UserSecretsClient()\n        hf_token = user_secrets.get_secret(\"HF_TOKEN\")   # use the label you created\n\n       # hf_token = userdata.get('HF_TOKEN')\n        login(hf_token#, add_to_git_credential=True\n         )\n\n    def load_model(self):#\"mistralai/Mistral-7B-Instruct-v0.2\"\n        # Load tokenizer and model\n        self.HFtokenloader()\n        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n        self.model = AutoModelForCausalLM.from_pretrained(\n            self.model_name,\n            torch_dtype=torch.float16,\n            device_map=\"auto\"      # automatically uses GPU/CPU\n        )\n\n    def get_emotion_sentiment(self):\n        # Emotion-based\n        return pipeline(\"text-classification\", model=\"bhadresh-savani/bert-base-uncased-emotion\", return_all_scores=True)\n\n    def get_domain_sentiment(self):\n        # Domain-based\n        return pipeline(\"text-classification\", model=\"unitary/toxic-bert\", return_all_scores=True)\n\n    def get_sentiment(self,sent_model, input: pd.Series):\n            return \"\".join([str(x['label'])+ \" : \"+ str(x['score']) for x in sent_model(input['subreddit'])[0]])\n\n    def get_sentimentdata(self):\n\n        #train_data = pd.read_csv('train.csv')\n        emotion_pipe = self.get_emotion_sentiment()\n        domain_pipe = self.get_domain_sentiment()\n        domain_pipedata=[]\n        emotion_pipedata=[]\n        for batch in more_itertools.batched(self.rawdata.iterrows(), 4):\n            emotion_pipedata+= [self.get_sentiment(emotion_pipe, x) for _, x in batch]\n            domain_pipedata+= [self.get_sentiment(domain_pipe, x) for _, x in batch]\n        self.rawdata['emotion_pipe']=emotion_pipedata\n        self.rawdata['domain_pipe']=domain_pipedata\n\n    def prompt(self,input: pd.Series):\n\n        return \"\"\"<start_of_turn>user\n              You are a really experienced moderator for the subreddit /r/%s. Your job\n              is to determine if the following reported comments violates the rule:\n              %s\n\n              %s\n              Decision:\n              True\n\n              %s\n              Decision:\n              False\n\n              %s\n              Decision:\n              False\n\n              %s\n              Decision:\n              True\n\n              %s\n\n              Emotion- based Sentiments\":\n              %s\n\n              Domain-based Sentiments:\n              %s\n\n              <end_of_turn>\n              <start_of_turn>model\\n\"\"\" % (\n                  input['subreddit'],\n                  input['rule'],\n                  \"\\n\".join([\"| \" + x for x in input['positive_example_1'].split('\\n')]),\n                  \"\\n\".join([\"| \" + x for x in input['negative_example_1'].split('\\n')]),\n                  \"\\n\".join([\"| \" + x for x in input['negative_example_2'].split('\\n')]),\n                  \"\\n\".join([\"| \" + x for x in input['positive_example_2'].split('\\n')]),\n                  \"\\n\".join([\"| \" + x for x in input['body'].split('\\n')]),\n                  \"\\n\".join(input['emotion_pipe']),\n                  \"\\n\".join(input['domain_pipe'])\n              )\n\n    def get_submission(self):\n        self.final_data  = self.rawdata[[\"row_id\",\"response\"]]\n        self.final_data.rename(columns={\"response\":\"rule_violation\"}, inplace=True)\n        self.final_data.to_csv(\"submission.csv\", index=False)\n\n\n    def predvalidation(self,threshold =0.5):\n        self.rawdata[\"pred\"] = [x > 0.46 for x in self.rawdata[\"response\"]]\n        auc_score = roc_auc_score(self.rawdata[\"rule_violation\"], self.rawdata[\"pred\"] )\n        print(f\"The ROC AUC score is: {auc_score}\")\n        return auc_score\n#train_data\n    def huggingFace_llmclassfier(self, data, traindata =0):\n        self.rawdata = data\n        responses = []\n        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n        if self.tokenizer.pad_token is None:\n            self.tokenizer.pad_token = self.tokenizer.eos_token\n        self.get_sentimentdata()\n        token_ids = [self.tokenizer.get_vocab()[word] for word in ['True', 'False']]\n        if any(token_id == self.tokenizer.get_vocab()['<unk>'] for token_id in token_ids):\n              raise ValueError('One of the target classes is not in the vocabulary.')\n        for batch in more_itertools.batched(self.rawdata.iterrows(), 4):\n            prompts = [self.prompt(x) for _, x in batch]\n            pre = self.tokenizer(text=prompts, return_tensors=\"pt\", padding=True,\n                            truncation=True,\n                            max_length=512).to(device)\n            with torch.no_grad():\n              outputs = self.model(**pre)\n            logits = outputs.logits[:, -1, token_ids]\n            probabilities = torch.softmax(logits, dim=-1)\n            responses.extend(probabilities[:, 0].tolist())\n\n        self.rawdata[\"response\"] = responses\n        if traindata==0:\n            self.get_submission()\n        return self.final_data\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T05:30:05.138200Z","iopub.execute_input":"2025-10-17T05:30:05.138924Z","iopub.status.idle":"2025-10-17T05:30:05.154501Z","shell.execute_reply.started":"2025-10-17T05:30:05.138898Z","shell.execute_reply":"2025-10-17T05:30:05.153778Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"HF_mistrial = reddit_evaluator(\"mistralai/Mistral-7B-Instruct-v0.2\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T05:30:08.189096Z","iopub.execute_input":"2025-10-17T05:30:08.189616Z","iopub.status.idle":"2025-10-17T05:31:05.966722Z","shell.execute_reply.started":"2025-10-17T05:30:08.189580Z","shell.execute_reply":"2025-10-17T05:31:05.966049Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\ntest_data = pd.read_csv('/kaggle/input/jigsaw-agile-community-rules/test.csv')\ntest_analysis = HF_mistrial.huggingFace_llmclassfier(test_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T05:31:05.967829Z","iopub.execute_input":"2025-10-17T05:31:05.968053Z","iopub.status.idle":"2025-10-17T05:31:23.526025Z","shell.execute_reply.started":"2025-10-17T05:31:05.968035Z","shell.execute_reply":"2025-10-17T05:31:23.525083Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_analysis.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T05:37:52.476006Z","iopub.execute_input":"2025-10-17T05:37:52.476511Z","iopub.status.idle":"2025-10-17T05:37:52.482424Z","shell.execute_reply.started":"2025-10-17T05:37:52.476485Z","shell.execute_reply":"2025-10-17T05:37:52.481746Z"}},"outputs":[],"execution_count":19}]}